{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "# from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):#, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages)#, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHSG0qPJP39GxIF1RUDhM6lePBCsP', 'finish_reason': 'stop', 'logprobs': None}, id='run-e8c6e213-2581-4977-867c-c718db40d83b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602beedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='9a570ffa-c51d-445d-bc32-a245b1b781c0'), AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHSG0qPJP39GxIF1RUDhM6lePBCsP', 'finish_reason': 'stop', 'logprobs': None}, id='run-e8c6e213-2581-4977-867c-c718db40d83b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f00edc0-cda7-64cd-8001-dd4073f81962'}}, metadata={'source': 'loop', 'writes': {'conversation': {'messages': AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHSG0qPJP39GxIF1RUDhM6lePBCsP', 'finish_reason': 'stop', 'logprobs': None}, id='run-e8c6e213-2581-4977-867c-c718db40d83b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}, 'thread_id': '1', 'step': 1, 'parents': {}}, created_at='2025-04-01T09:31:11.972270+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f00edc0-bc6a-6d43-8000-451e082d2394'}}, tasks=())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91588f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! How's it going? What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced75de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='9a570ffa-c51d-445d-bc32-a245b1b781c0'), AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHSG0qPJP39GxIF1RUDhM6lePBCsP', 'finish_reason': 'stop', 'logprobs': None}, id='run-e8c6e213-2581-4977-867c-c718db40d83b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='053707c7-5082-40f0-ac93-a625d609fdea'), AIMessage(content=\"Hi Lance! How's it going? What can I do for you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 33, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BHSHfqrbIqRxgQRU9lXx8F0qI0pQY', 'finish_reason': 'stop', 'logprobs': None}, id='run-5245460a-b084-4d23-824b-a75ac5a05015-0', usage_metadata={'input_tokens': 33, 'output_tokens': 17, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f00edc4-a2eb-6a28-8004-f2678e52b69a'}}, metadata={'source': 'loop', 'writes': {'conversation': {'messages': AIMessage(content=\"Hi Lance! How's it going? What can I do for you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 33, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BHSHfqrbIqRxgQRU9lXx8F0qI0pQY', 'finish_reason': 'stop', 'logprobs': None}, id='run-5245460a-b084-4d23-824b-a75ac5a05015-0', usage_metadata={'input_tokens': 33, 'output_tokens': 17, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}, 'thread_id': '1', 'step': 4, 'parents': {}}, created_at='2025-04-01T09:32:54.865565+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f00edc4-9ba0-6125-8003-52840607d845'}}, tasks=())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6d84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14beaef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='9a570ffa-c51d-445d-bc32-a245b1b781c0'),\n",
       "  AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHSG0qPJP39GxIF1RUDhM6lePBCsP', 'finish_reason': 'stop', 'logprobs': None}, id='run-e8c6e213-2581-4977-867c-c718db40d83b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='053707c7-5082-40f0-ac93-a625d609fdea'),\n",
       "  AIMessage(content=\"Hi Lance! How's it going? What can I do for you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 33, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BHSHfqrbIqRxgQRU9lXx8F0qI0pQY', 'finish_reason': 'stop', 'logprobs': None}, id='run-5245460a-b084-4d23-824b-a75ac5a05015-0', usage_metadata={'input_tokens': 33, 'output_tokens': 17, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c82fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance! How can I assist you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f575450e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='d445c593-bb27-407f-b46d-0190d429f003'),\n",
       "  AIMessage(content='Hello Lance! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 11, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHSKSqpCz283Jqtwr2yojvtVfCV2Y', 'finish_reason': 'stop', 'logprobs': None}, id='run-5c3c9b4f-0342-4080-953e-e220548b0b21-0', usage_metadata={'input_tokens': 11, 'output_tokens': 11, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = graph.get_state(config)\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c8b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: __start__. Type: on_chain_start. Name: __start__\n",
      "Node: __start__. Type: on_chain_start. Name: _write\n",
      "Node: __start__. Type: on_chain_end. Name: _write\n",
      "Node: __start__. Type: on_chain_start. Name: _write\n",
      "Node: __start__. Type: on_chain_end. Name: _write\n",
      "Node: __start__. Type: on_chain_stream. Name: __start__\n",
      "Node: __start__. Type: on_chain_end. Name: __start__\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: _write\n",
      "Node: conversation. Type: on_chain_end. Name: _write\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' American', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Area', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' compete', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' club', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' founded', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' charter', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' All', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-Amer', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ica', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='AA', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' joined', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' leagues', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' merged', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Key', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Points', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='St', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='adium', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' play', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Levi', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' moved', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Before', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' played', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Cand', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='lestick', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Park', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Masc', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ot', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' colors', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' red', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' gold', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' white', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' mascot', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' S', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ourd', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ough', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Sam', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='Champ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ionship', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='X', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='VI', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='III', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='IV', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' successful', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' period', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' being', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' early', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='199', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' conference', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='Not', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Joe', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Jerry', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Steve', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Ronnie', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' L', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ott', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Charles', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Haley', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' were', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' instrumental', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' during', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' championship', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='Co', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='aching', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Management', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' coaches', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Bill', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' credited', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' popular', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='izing', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' offense', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' George', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Se', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='if', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ert', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' As', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' coach', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Kyle', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Shan', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ahan', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='R', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ival', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' intense', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' notably', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Dallas', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Cowboys', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Los', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Angeles', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Rams', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Seattle', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' These', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' fueled', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' high', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-st', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='akes', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' playoff', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' match', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ups', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='Recent', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Performance', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' reaching', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' losing', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' City', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' Chiefs', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' building', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' mix', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' veteran', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' leadership', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' young', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' talent', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' contributions', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' both', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' terms', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='-field', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' innovations', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content=' game', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719'}, id='run-d58414ba-13e9-4ac0-a84c-01dec6c34ae7')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| the| San| Francisco| Bay| Area|.| They| compete| in| the| National| Football| League| (|NFL|)| as| a| member| club| of| the| league|'s| National| Football| Conference| (|N|FC|)| West| division|.| The| team| was| founded| in| |194|6| as| a| charter| member| of| the| All|-Amer|ica| Football| Conference| (|AA|FC|)| and| joined| the| NFL| in| |194|9| when| the| leagues| merged|.\n",
      "\n",
      "|###| Key| Points|:\n",
      "\n",
      "|-| **|St|adium|**|:| The| |49|ers| play| their| home| games| at| Levi|'s| Stadium| in| Santa| Clara|,| California|,| which| they| moved| to| in| |201|4|.| Before| that|,| they| played| at| Cand|lestick| Park| in| San| Francisco|.\n",
      "\n",
      "|-| **|Team| Colors|**|:| The| team's| colors| are| red|,| gold|,| and| white|.\n",
      "\n",
      "|-| **|Masc|ot|**|:| The| |49|ers|'| mascot| is| S|ourd|ough| Sam|.\n",
      "\n",
      "|-| **|Champ|ionship|s|**|:| The| |49|ers| have| won| five| Super| Bowl| titles| (|X|VI|,| XIX|,| XX|III|,| XX|IV|,| and| XX|IX|),| with| their| most| successful| period| being| the| |198|0|s| and| early| |199|0|s|.| They| have| also| won| numerous| division| titles| and| conference| championships|.\n",
      "\n",
      "|-| **|Not|able| Players|**|:| The| team| has| had| several| Hall| of| Fame| players|,| including| Joe| Montana|,| Jerry| Rice|,| Steve| Young|,| Ronnie| L|ott|,| and| Charles| Haley|.| Jerry| Rice| is| often| considered| one| of| the| greatest| wide| receivers| in| NFL| history|.\n",
      "\n",
      "|-| **|Co|aching| and| Management|**|:| The| team| has| been| led| by| several| notable| coaches|,| including| Bill| Walsh|,| who| is| credited| with| popular|izing| the| West| Coast| offense|.| As| of| the| |202|3| season|,| the| head| coach| is| Kyle| Shan|ahan|.\n",
      "\n",
      "|-| **|R|ival|ries|**|:| The| |49|ers| have| notable| rival|ries| with| the| Seattle| Seahawks|,| Los| Angeles| Rams|,| and| historically| with| the| Dallas| Cowboys| and| Green| Bay| Packers|.\n",
      "\n",
      "|-| **|Recent| Performance|**|:| In| recent| years|,| the| |49|ers| have| been| competitive|,| reaching| the| Super| Bowl| in| the| |201|9| season| but| losing| to| the| Kansas| City| Chiefs|.| They| have| been| known| for| a| strong| defense| and| a| dynamic| offense| under| coach| Kyle| Shan|ahan|.\n",
      "\n",
      "|The| |49|ers| have| a| rich| history| and| a| passionate| fan| base|,| making| them| one| of| the| iconic| franchises| in| the| NFL|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "Yoo should see the following output:\n",
    "```\n",
    "-  API: http://127.0.0.1:2024\n",
    "-  Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "-  API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94d08dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7',\n",
       "  'graph_id': 'chatbot',\n",
       "  'config': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'chatbot',\n",
       "  'created_at': '2025-03-31T09:15:28.543436+00:00',\n",
       "  'updated_at': '2025-03-31T09:15:28.543436+00:00',\n",
       "  'version': 1}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa6cc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8469f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thread_id': '4894fca3-406c-44f9-a158-5304bfe915df',\n",
       " 'created_at': '2025-04-01T10:56:54.226284+00:00',\n",
       " 'updated_at': '2025-04-01T10:56:54.226284+00:00',\n",
       " 'metadata': {},\n",
       " 'status': 'idle',\n",
       " 'config': {},\n",
       " 'values': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1f00ee82-6140-68a0-96be-49337f8f5cf6', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'b5b7dc85-acb4-4f6d-82e2-3871a5745d32', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'b5b7dc85-acb4-4f6d-82e2-3871a5745d32', 'example': False}, {'content': '2 multiplied by 3 equals 6.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 10, 'prompt_tokens': 13, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHTbqOMU61IIhanBr4lsf3iUj64j2', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-981832fd-3834-429d-9152-ad1a034bea26-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 13, 'output_tokens': 10, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"chatbot\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='9031d556-cea3-4e50-ab42-1e15e3256bf9'\n",
      "=========================\n",
      "content='2 multiplied by 3 equals 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 36, 'output_tokens': 10, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 36, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BHTeCbFal9JM37Td98tfVCeOhPv3u', 'finish_reason': 'stop', 'logprobs': None} id='run-3769225f-3eab-43e6-9470-619403efc250-0'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "# thread = await client.threads.create()\n",
    "\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"chatbot\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"chatbot\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a87d019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'run_id': '1f00ee99-782b-6d61-a1da-10909617015b', 'attempt': 1}\n",
      "messages/metadata: {'run-84cbcf1c-6c14-4274-a4ca-183660524ec3': {'metadata': {'created_by': 'system', 'graph_id': 'chatbot', 'assistant_id': '8a4ac7a4-50eb-5206-98cc-4a72345cb1f7', 'run_attempt': 1, 'langgraph_version': '0.3.18', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_auth_user_id': '', 'run_id': '1f00ee99-782b-6d61-a1da-10909617015b', 'thread_id': '22072dc5-6e6e-4653-b416-412e4776bf98', 'user_id': '', 'langgraph_step': 4, 'langgraph_node': 'conversation', 'langgraph_triggers': ['branch:to:conversation', 'start:conversation'], 'langgraph_path': ['__pregel_pull', 'conversation'], 'langgraph_checkpoint_ns': 'conversation:29ecbdc4-26e6-6d27-2245-dc74d4dc8e00', 'checkpoint_ns': 'conversation:29ecbdc4-26e6-6d27-2245-dc74d4dc8e00', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': 0.0}}}\n",
      "messages/partial: [{'content': '', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by ', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by 3 equals', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by 3 equals ', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by 3 equals 6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by 3 equals 6.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "messages/partial: [{'content': '2 multiplied by 3 equals 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90'}, 'type': 'ai', 'name': None, 'id': 'run-84cbcf1c-6c14-4274-a4ca-183660524ec3', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n"
     ]
    }
   ],
   "source": [
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"chatbot\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(f\"{event.event}: {event.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d743cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1f00eea4-81ff-69a2-adf1-405b764547a6\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: 2\n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied\n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by\n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by \n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by 3\n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by 3 equals\n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by 3 equals \n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by 3 equals 6\n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by 3 equals 6.\n",
      "--------------------------------------------------\n",
      "AI: 2 multiplied by 3 equals 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"chatbot\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if {}:\n",
    "    print(\"here\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
